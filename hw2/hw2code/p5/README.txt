For problem 5, we have 1 script for each representation and other 
helper scripts.

The main code in unigram.py, tfidf.py and bigram.py are the same, we 
detailly comment unigram.py and only comment tfidf.py and bigram.py 
where they are different with unigram.py

For some suporting files:
1. The cutout.py is used for spliting the original training and testing dataset to smaller ones such that we can compare the dataset size's impact on accuracy.
2. The sort_weight.py is used for getting the highest 10 and lowest 10 weighted words from classifiers. 
